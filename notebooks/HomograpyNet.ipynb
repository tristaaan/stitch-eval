{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Homography Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TWright\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3184007216431629236\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3433345024\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8338772392718503246\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x4fca128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC'\n",
    "tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "Read the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fname</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Tp26_Y000_X000_040_0000</td>\n",
       "      <td>-27,-16,-15,-5,-30,-25,-4,26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tp26_Y000_X000_040_0001</td>\n",
       "      <td>0,-24,-8,7,-26,18,-13,-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tp26_Y000_X000_040_0002</td>\n",
       "      <td>-18,-2,21,-8,13,26,25,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tp26_Y000_X000_040_0003</td>\n",
       "      <td>25,-9,-30,-5,-6,18,-19,-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tp26_Y000_X000_040_0004</td>\n",
       "      <td>-8,4,-10,9,-13,2,-32,-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    fname                             h\n",
       "0           0  Tp26_Y000_X000_040_0000  -27,-16,-15,-5,-30,-25,-4,26\n",
       "1           1  Tp26_Y000_X000_040_0001      0,-24,-8,7,-26,18,-13,-6\n",
       "2           2  Tp26_Y000_X000_040_0002       -18,-2,21,-8,13,26,25,4\n",
       "3           3  Tp26_Y000_X000_040_0003     25,-9,-30,-5,-6,18,-19,-6\n",
       "4           4  Tp26_Y000_X000_040_0004      -8,4,-10,9,-13,2,-32,-23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "train_split = 0.8\n",
    "valid_split = 0.2\n",
    "\n",
    "def load_img_paths(target):\n",
    "    '''\n",
    "    Retrieve the full path of all images in the dataset\n",
    "    '''\n",
    "    return glob.glob(target + '/*.tif')\n",
    "\n",
    "data_dir = r'../data'\n",
    "original_data_dir = path.join(data_dir, 'hnet_training')\n",
    "all_files = pd.read_csv(path.join(original_data_dir, 'homographies.tsv'), sep='\\t')\n",
    "all_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning images:    48000\n",
      "Validation images: 12000\n"
     ]
    }
   ],
   "source": [
    "all_files = all_files.sample(frac=1, random_state=123) # shuffle with seed 123 for reproducability\n",
    "train_paths = []\n",
    "valid_paths = []\n",
    "\n",
    "if train_split <= 1:\n",
    "    frac = int(all_files.shape[0] * train_split)\n",
    "    train_paths = all_files[:frac].values.tolist()\n",
    "    valid_paths = all_files[frac:].values.tolist()\n",
    "else:\n",
    "    valid_frac = int(train_split * valid_split)\n",
    "    train_paths = all_files[:train_split].values.tolist()\n",
    "    valid_paths = all_files[train_split:train_split+valid_frac].values.tolist()\n",
    "\n",
    "assert(len(train_paths) > 0)\n",
    "print('Traning images:    %d' % len(train_paths))\n",
    "print('Validation images: %d' % len(valid_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HomographyNet\n",
    "\n",
    "Regression variant\n",
    "\n",
    "> We use 8 convolutional layers with a max pooling layer (2x2, stride 2) after every two convolutions. The 8 convolutional layers have the following number of filters per layer: 64 [x4], 128 [x4]. The convolutional layers are followed by two fully connected layers. The first fully connected layer has 1024 units. Dropout with a probability of 0.5 is applied after the final convolutional layer and the first fully-connected layer.\n",
    "\n",
    "> The regression network directly produces 8 real-valued\n",
    "numbers and uses the Euclidean (L2) loss as the final layer\n",
    "during training.\n",
    "\n",
    "> using stochastic gradient descent (SGD) with momentum of 0.9. We use a base learning rate of 0.005 and decrease the learning rate by a factor of 10 after every 30,000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Dense, Flatten, MaxPooling2D, Input, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "import keras.backend as K\n",
    "\n",
    "def euclidean_distance(y_true, y_pred):\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(y_pred - y_true), axis=-1, keepdims=True), K.epsilon()))\n",
    "\n",
    "def conv_block(m, filters):\n",
    "    kernel = (3, 3)\n",
    "    m = Conv2D(filters, kernel, padding='same', activation='relu')(m)\n",
    "    m = Conv2D(filters, kernel, padding='same', activation='relu')(m)\n",
    "    m = BatchNormalization()(m)\n",
    "    return MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(m)\n",
    "\n",
    "def homography_regression_model(input_dims):\n",
    "    input_shape=(*input_dims, 2)\n",
    "    \n",
    "    input_layer = Input(shape=input_shape, name='input_layer')\n",
    "    \n",
    "    # 4x 64\n",
    "    x = conv_block(input_layer, 64)\n",
    "    x = conv_block(x,           64) \n",
    "    # 4x 128\n",
    "    x = conv_block(x,           128)\n",
    "    x = Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1024, name='FC_1024')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    out = Dense(8, name='output')(x)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 128, 128, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 128, 128, 64)      1216      \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "FC_1024 (Dense)              (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 34,193,800\n",
      "Trainable params: 34,193,032\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from skimage.io import imread\n",
    "\n",
    "img_size = (128, 128)\n",
    "\n",
    "opt = SGD(lr=0.005, momentum=0.9, decay=0.0015)\n",
    "\n",
    "my_model = homography_regression_model(img_size)\n",
    "my_model.compile(optimizer=opt, loss=euclidean_distance)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Generators\n",
    "\n",
    "We generate the \"seemingly infinite training data\" on the fly by using Keras' DataGenerators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp directory already exists\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from os import path\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import Sequence\n",
    "from skimage.transform import resize, rotate\n",
    "\n",
    "def h_string_to_arr(s):\n",
    "    return np.array(list(map(lambda x: np.float32(x), row['h'].split(','))))\n",
    "\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "class DataGenerator(Sequence):\n",
    "    '''\n",
    "    Adapted from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "    Allows for multiprocessing in the fit generator\n",
    "    '''\n",
    "\n",
    "    def __init__(self, train_set, batch_size, im_size, train_dir):\n",
    "        self.train = train_set\n",
    "        self.batch_size = batch_size\n",
    "        self.im_size = im_size\n",
    "        self.train_dir = train_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.train) / float(self.batch_size)))\n",
    "\n",
    "    def read_images(self, fname):\n",
    "        ext = '.tif'\n",
    "        base = path.join(self.train_dir, fname)\n",
    "        a = img_to_array(load_img(base + '_A' + ext, grayscale=True))\n",
    "        b = img_to_array(load_img(base + '_B' + ext, grayscale=True))\n",
    "        return np.dstack((a,b))\n",
    "    \n",
    "    # Will output sequence of tuples (image, test) given a datapath\n",
    "    def __getitem__(self, idx):\n",
    "        X = np.zeros(shape=(batch_size, self.im_size[0], self.im_size[1], 2))\n",
    "        y = np.zeros(shape=(batch_size, 8))\n",
    "        batch = self.train[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        for j,row in enumerate(batch):\n",
    "            fname, h_str = row[1:]\n",
    "            X[j] = self.read_images(fname)\n",
    "            y[j] = h_string_to_arr(h_str)\n",
    "        return (X, y)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# create weights file if it doesn't exist for ModelCheckpoint\n",
    "from os import mkdir\n",
    "try: \n",
    "    mkdir('tmp')\n",
    "except FileExistsError:\n",
    "    print('tmp directory already exists')\n",
    "\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "> The networks are trained for for 90,000 total iterations using a batch size of 64.\n",
    "\n",
    "No words on how many epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning images:    48000\n",
      "Validation images: 12000\n",
      "Training steps:    750\n",
      "Validation steps:  187\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs     = 50\n",
    "\n",
    "steps_per_epoch  = int(len(train_paths) / batch_size)\n",
    "validation_steps = int(len(valid_paths) / batch_size)\n",
    "\n",
    "training_generator   = DataGenerator(train_paths, batch_size, img_size, original_data_dir)\n",
    "validation_generator = DataGenerator(valid_paths, batch_size, img_size, original_data_dir)\n",
    "\n",
    "# descriptive weight file naming\n",
    "checkpointer = ModelCheckpoint(filepath=('tmp/weights-%d-%d.hdf5' % \n",
    "                                         (batch_size, img_size[0])), \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "print('Traning images:    %d' % len(train_paths))\n",
    "print('Validation images: %d' % len(valid_paths))\n",
    "print('Training steps:    %d' % steps_per_epoch)\n",
    "print('Validation steps:  %d' % validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 202s - loss: 4.4354 - val_loss: 1.0570\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05704, saving model to tmp/weights-64-128.hdf5\n",
      "Epoch 2/50\n",
      " - 202s - loss: 1.9004 - val_loss: 0.5583\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.05704 to 0.55825, saving model to tmp/weights-64-128.hdf5\n",
      "Epoch 3/50\n",
      " - 203s - loss: 1.4889 - val_loss: 0.3257\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55825 to 0.32574, saving model to tmp/weights-64-128.hdf5\n",
      "Epoch 4/50\n"
     ]
    }
   ],
   "source": [
    "hist = my_model.fit_generator(training_generator,\n",
    "                              validation_data=validation_generator,\n",
    "                              epochs=epochs,\n",
    "                              workers=3,\n",
    "                              verbose=2,\n",
    "                              callbacks=[history, checkpointer, early_stopping]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
